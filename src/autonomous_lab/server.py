#!/usr/bin/env python3
"""
MCP Feedback Enhanced ä¼ºæœå™¨ä¸»è¦æ¨¡çµ„

æ­¤æ¨¡çµ„æä¾› MCP (Model Context Protocol) çš„å¢å¼·å›é¥‹æ”¶é›†åŠŸèƒ½ï¼Œ
æ”¯æ´æ™ºèƒ½ç’°å¢ƒæª¢æ¸¬ï¼Œè‡ªå‹•ä½¿ç”¨ Web UI ä»‹é¢ã€‚

ä¸»è¦åŠŸèƒ½ï¼š
- MCP å·¥å…·å¯¦ç¾
- ä»‹é¢é¸æ“‡ï¼ˆWeb UIï¼‰
- ç’°å¢ƒæª¢æ¸¬ (SSH Remote, WSL, Local)
- åœ‹éš›åŒ–æ”¯æ´
- åœ–ç‰‡è™•ç†èˆ‡ä¸Šå‚³
- å‘½ä»¤åŸ·è¡Œèˆ‡çµæœå±•ç¤º
- å°ˆæ¡ˆç›®éŒ„ç®¡ç†

ä¸»è¦ MCP å·¥å…·ï¼š
- interactive_feedback: æ”¶é›†ç”¨æˆ¶äº’å‹•å›é¥‹
- get_system_info: ç²å–ç³»çµ±ç’°å¢ƒè³‡è¨Š

ä½œè€…: FÃ¡bio Ferreira (åŸä½œè€…)
å¢å¼·: Minidoracat (Web UI, åœ–ç‰‡æ”¯æ´, ç’°å¢ƒæª¢æ¸¬)
é‡æ§‹: æ¨¡å¡ŠåŒ–è¨­è¨ˆ
"""

import base64
import io
import json
import os
import sys
from typing import Annotated, Any

from fastmcp import FastMCP
from fastmcp.utilities.types import Image as MCPImage
from mcp.types import TextContent
from pydantic import Field

# å°å…¥çµ±ä¸€çš„èª¿è©¦åŠŸèƒ½
from .debug import server_debug_log as debug_log

# å°å…¥å¤šèªç³»æ”¯æ´
# å°å…¥éŒ¯èª¤è™•ç†æ¡†æ¶
from .utils.error_handler import ErrorHandler, ErrorType

# å°å…¥è³‡æºç®¡ç†å™¨
from .utils.resource_manager import create_temp_file


# ===== ç·¨ç¢¼åˆå§‹åŒ– =====
def init_encoding():
    """åˆå§‹åŒ–ç·¨ç¢¼è¨­ç½®ï¼Œç¢ºä¿æ­£ç¢ºè™•ç†ä¸­æ–‡å­—ç¬¦"""
    try:
        # Windows ç‰¹æ®Šè™•ç†
        if sys.platform == "win32":
            import msvcrt

            # è¨­ç½®ç‚ºäºŒé€²åˆ¶æ¨¡å¼
            msvcrt.setmode(sys.stdin.fileno(), os.O_BINARY)
            msvcrt.setmode(sys.stdout.fileno(), os.O_BINARY)

            # é‡æ–°åŒ…è£ç‚º UTF-8 æ–‡æœ¬æµï¼Œä¸¦ç¦ç”¨ç·©è¡
            # ä¿®å¾© union-attr éŒ¯èª¤ - å®‰å…¨ç²å– buffer æˆ– detach
            stdin_buffer = getattr(sys.stdin, "buffer", None)
            if stdin_buffer is None and hasattr(sys.stdin, "detach"):
                stdin_buffer = sys.stdin.detach()

            stdout_buffer = getattr(sys.stdout, "buffer", None)
            if stdout_buffer is None and hasattr(sys.stdout, "detach"):
                stdout_buffer = sys.stdout.detach()

            sys.stdin = io.TextIOWrapper(
                stdin_buffer, encoding="utf-8", errors="replace", newline=None
            )
            sys.stdout = io.TextIOWrapper(
                stdout_buffer,
                encoding="utf-8",
                errors="replace",
                newline="",
                write_through=True,  # é—œéµï¼šç¦ç”¨å¯«å…¥ç·©è¡
            )
        else:
            # é Windows ç³»çµ±çš„æ¨™æº–è¨­ç½®
            if hasattr(sys.stdout, "reconfigure"):
                sys.stdout.reconfigure(encoding="utf-8", errors="replace")
            if hasattr(sys.stdin, "reconfigure"):
                sys.stdin.reconfigure(encoding="utf-8", errors="replace")

        # è¨­ç½® stderr ç·¨ç¢¼ï¼ˆç”¨æ–¼èª¿è©¦è¨Šæ¯ï¼‰
        if hasattr(sys.stderr, "reconfigure"):
            sys.stderr.reconfigure(encoding="utf-8", errors="replace")

        return True
    except Exception:
        # å¦‚æœç·¨ç¢¼è¨­ç½®å¤±æ•—ï¼Œå˜—è©¦åŸºæœ¬è¨­ç½®
        try:
            if hasattr(sys.stdout, "reconfigure"):
                sys.stdout.reconfigure(encoding="utf-8", errors="replace")
            if hasattr(sys.stdin, "reconfigure"):
                sys.stdin.reconfigure(encoding="utf-8", errors="replace")
            if hasattr(sys.stderr, "reconfigure"):
                sys.stderr.reconfigure(encoding="utf-8", errors="replace")
        except:
            pass
        return False


# åˆå§‹åŒ–ç·¨ç¢¼ï¼ˆåœ¨å°å…¥æ™‚å°±åŸ·è¡Œï¼‰
_encoding_initialized = init_encoding()

# ===== å¸¸æ•¸å®šç¾© =====
SERVER_NAME = "Autonomous Lab MCP"
SSH_ENV_VARS = ["SSH_CONNECTION", "SSH_CLIENT", "SSH_TTY"]
REMOTE_ENV_VARS = ["REMOTE_CONTAINERS", "CODESPACES"]


# åˆå§‹åŒ– MCP æœå‹™å™¨
from . import __version__


# ç¢ºä¿ log_level è¨­å®šç‚ºæ­£ç¢ºçš„å¤§å¯«æ ¼å¼
fastmcp_settings = {}

# æª¢æŸ¥ç’°å¢ƒè®Šæ•¸ä¸¦è¨­å®šæ­£ç¢ºçš„ log_level
env_log_level = os.getenv("FASTMCP_LOG_LEVEL", "").upper()
if env_log_level in ("DEBUG", "INFO", "WARNING", "ERROR", "CRITICAL"):
    fastmcp_settings["log_level"] = env_log_level
else:
    # é è¨­ä½¿ç”¨ INFO ç­‰ç´š
    fastmcp_settings["log_level"] = "INFO"

mcp: Any = FastMCP(SERVER_NAME)


# ===== å·¥å…·å‡½æ•¸ =====
def is_wsl_environment() -> bool:
    """
    æª¢æ¸¬æ˜¯å¦åœ¨ WSL (Windows Subsystem for Linux) ç’°å¢ƒä¸­é‹è¡Œ

    Returns:
        bool: True è¡¨ç¤º WSL ç’°å¢ƒï¼ŒFalse è¡¨ç¤ºå…¶ä»–ç’°å¢ƒ
    """
    try:
        # æª¢æŸ¥ /proc/version æ–‡ä»¶æ˜¯å¦åŒ…å« WSL æ¨™è­˜
        if os.path.exists("/proc/version"):
            with open("/proc/version") as f:
                version_info = f.read().lower()
                if "microsoft" in version_info or "wsl" in version_info:
                    debug_log("åµæ¸¬åˆ° WSL ç’°å¢ƒï¼ˆé€šé /proc/versionï¼‰")
                    return True

        # æª¢æŸ¥ WSL ç›¸é—œç’°å¢ƒè®Šæ•¸
        wsl_env_vars = ["WSL_DISTRO_NAME", "WSL_INTEROP", "WSLENV"]
        for env_var in wsl_env_vars:
            if os.getenv(env_var):
                debug_log(f"åµæ¸¬åˆ° WSL ç’°å¢ƒè®Šæ•¸: {env_var}")
                return True

        # æª¢æŸ¥æ˜¯å¦å­˜åœ¨ WSL ç‰¹æœ‰çš„è·¯å¾‘
        wsl_paths = ["/mnt/c", "/mnt/d", "/proc/sys/fs/binfmt_misc/WSLInterop"]
        for path in wsl_paths:
            if os.path.exists(path):
                debug_log(f"åµæ¸¬åˆ° WSL ç‰¹æœ‰è·¯å¾‘: {path}")
                return True

    except Exception as e:
        debug_log(f"WSL æª¢æ¸¬éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")

    return False


def is_remote_environment() -> bool:
    """
    æª¢æ¸¬æ˜¯å¦åœ¨é ç«¯ç’°å¢ƒä¸­é‹è¡Œ

    Returns:
        bool: True è¡¨ç¤ºé ç«¯ç’°å¢ƒï¼ŒFalse è¡¨ç¤ºæœ¬åœ°ç’°å¢ƒ
    """
    # WSL ä¸æ‡‰è¢«è¦–ç‚ºé ç«¯ç’°å¢ƒï¼Œå› ç‚ºå®ƒå¯ä»¥è¨ªå• Windows ç€è¦½å™¨
    if is_wsl_environment():
        debug_log("WSL ç’°å¢ƒä¸è¢«è¦–ç‚ºé ç«¯ç’°å¢ƒ")
        return False

    # æª¢æŸ¥ SSH é€£ç·šæŒ‡æ¨™
    for env_var in SSH_ENV_VARS:
        if os.getenv(env_var):
            debug_log(f"åµæ¸¬åˆ° SSH ç’°å¢ƒè®Šæ•¸: {env_var}")
            return True

    # æª¢æŸ¥é ç«¯é–‹ç™¼ç’°å¢ƒ
    for env_var in REMOTE_ENV_VARS:
        if os.getenv(env_var):
            debug_log(f"åµæ¸¬åˆ°é ç«¯é–‹ç™¼ç’°å¢ƒ: {env_var}")
            return True

    # æª¢æŸ¥ Docker å®¹å™¨
    if os.path.exists("/.dockerenv"):
        debug_log("åµæ¸¬åˆ° Docker å®¹å™¨ç’°å¢ƒ")
        return True

    # Windows é ç«¯æ¡Œé¢æª¢æŸ¥
    if sys.platform == "win32":
        session_name = os.getenv("SESSIONNAME", "")
        if session_name and "RDP" in session_name:
            debug_log(f"åµæ¸¬åˆ° Windows é ç«¯æ¡Œé¢: {session_name}")
            return True

    # Linux ç„¡é¡¯ç¤ºç’°å¢ƒæª¢æŸ¥ï¼ˆä½†æ’é™¤ WSLï¼‰
    if (
        sys.platform.startswith("linux")
        and not os.getenv("DISPLAY")
        and not is_wsl_environment()
    ):
        debug_log("åµæ¸¬åˆ° Linux ç„¡é¡¯ç¤ºç’°å¢ƒ")
        return True

    return False


def save_feedback_to_file(feedback_data: dict, file_path: str | None = None) -> str:
    """
    å°‡å›é¥‹è³‡æ–™å„²å­˜åˆ° JSON æ–‡ä»¶

    Args:
        feedback_data: å›é¥‹è³‡æ–™å­—å…¸
        file_path: å„²å­˜è·¯å¾‘ï¼Œè‹¥ç‚º None å‰‡è‡ªå‹•ç”¢ç”Ÿè‡¨æ™‚æ–‡ä»¶

    Returns:
        str: å„²å­˜çš„æ–‡ä»¶è·¯å¾‘
    """
    if file_path is None:
        # ä½¿ç”¨è³‡æºç®¡ç†å™¨å‰µå»ºè‡¨æ™‚æ–‡ä»¶
        file_path = create_temp_file(suffix=".json", prefix="feedback_")

    # ç¢ºä¿ç›®éŒ„å­˜åœ¨
    directory = os.path.dirname(file_path)
    if directory and not os.path.exists(directory):
        os.makedirs(directory, exist_ok=True)

    # è¤‡è£½æ•¸æ“šä»¥é¿å…ä¿®æ”¹åŸå§‹æ•¸æ“š
    json_data = feedback_data.copy()

    # è™•ç†åœ–ç‰‡æ•¸æ“šï¼šå°‡ bytes è½‰æ›ç‚º base64 å­—ç¬¦ä¸²ä»¥ä¾¿ JSON åºåˆ—åŒ–
    if "images" in json_data and isinstance(json_data["images"], list):
        processed_images = []
        for img in json_data["images"]:
            if isinstance(img, dict) and "data" in img:
                processed_img = img.copy()
                # å¦‚æœ data æ˜¯ bytesï¼Œè½‰æ›ç‚º base64 å­—ç¬¦ä¸²
                if isinstance(img["data"], bytes):
                    processed_img["data"] = base64.b64encode(img["data"]).decode(
                        "utf-8"
                    )
                    processed_img["data_type"] = "base64"
                processed_images.append(processed_img)
            else:
                processed_images.append(img)
        json_data["images"] = processed_images

    # å„²å­˜è³‡æ–™
    with open(file_path, "w", encoding="utf-8") as f:
        json.dump(json_data, f, ensure_ascii=False, indent=2)

    debug_log(f"å›é¥‹è³‡æ–™å·²å„²å­˜è‡³: {file_path}")
    return file_path


def create_feedback_text(feedback_data: dict) -> str:
    """
    å»ºç«‹æ ¼å¼åŒ–çš„å›é¥‹æ–‡å­—

    Args:
        feedback_data: å›é¥‹è³‡æ–™å­—å…¸

    Returns:
        str: æ ¼å¼åŒ–å¾Œçš„å›é¥‹æ–‡å­—
    """
    text_parts = []

    # åŸºæœ¬å›é¥‹å…§å®¹
    if feedback_data.get("interactive_feedback"):
        text_parts.append(f"=== ç”¨æˆ¶å›é¥‹ ===\n{feedback_data['interactive_feedback']}")

    # å‘½ä»¤åŸ·è¡Œæ—¥èªŒ
    if feedback_data.get("command_logs"):
        text_parts.append(f"=== å‘½ä»¤åŸ·è¡Œæ—¥èªŒ ===\n{feedback_data['command_logs']}")

    # åœ–ç‰‡é™„ä»¶æ¦‚è¦
    if feedback_data.get("images"):
        images = feedback_data["images"]
        text_parts.append(f"=== åœ–ç‰‡é™„ä»¶æ¦‚è¦ ===\nç”¨æˆ¶æä¾›äº† {len(images)} å¼µåœ–ç‰‡ï¼š")

        for i, img in enumerate(images, 1):
            size = img.get("size", 0)
            name = img.get("name", "unknown")

            # æ™ºèƒ½å–®ä½é¡¯ç¤º
            if size < 1024:
                size_str = f"{size} B"
            elif size < 1024 * 1024:
                size_kb = size / 1024
                size_str = f"{size_kb:.1f} KB"
            else:
                size_mb = size / (1024 * 1024)
                size_str = f"{size_mb:.1f} MB"

            img_info = f"  {i}. {name} ({size_str})"

            # ç‚ºæé«˜å…¼å®¹æ€§ï¼Œæ·»åŠ  base64 é è¦½ä¿¡æ¯
            if img.get("data"):
                try:
                    if isinstance(img["data"], bytes):
                        img_base64 = base64.b64encode(img["data"]).decode("utf-8")
                    elif isinstance(img["data"], str):
                        img_base64 = img["data"]
                    else:
                        img_base64 = None

                    if img_base64:
                        # åªé¡¯ç¤ºå‰50å€‹å­—ç¬¦çš„é è¦½
                        preview = (
                            img_base64[:50] + "..."
                            if len(img_base64) > 50
                            else img_base64
                        )
                        img_info += f"\n     Base64 é è¦½: {preview}"
                        img_info += f"\n     å®Œæ•´ Base64 é•·åº¦: {len(img_base64)} å­—ç¬¦"

                        # å¦‚æœ AI åŠ©æ‰‹ä¸æ”¯æ´ MCP åœ–ç‰‡ï¼Œå¯ä»¥æä¾›å®Œæ•´ base64
                        debug_log(f"åœ–ç‰‡ {i} Base64 å·²æº–å‚™ï¼Œé•·åº¦: {len(img_base64)}")

                        # æª¢æŸ¥æ˜¯å¦å•Ÿç”¨ Base64 è©³ç´°æ¨¡å¼ï¼ˆå¾ UI è¨­å®šä¸­ç²å–ï¼‰
                        include_full_base64 = feedback_data.get("settings", {}).get(
                            "enable_base64_detail", False
                        )

                        if include_full_base64:
                            # æ ¹æ“šæª”æ¡ˆåæ¨æ–· MIME é¡å‹
                            file_name = img.get("name", "image.png")
                            if file_name.lower().endswith((".jpg", ".jpeg")):
                                mime_type = "image/jpeg"
                            elif file_name.lower().endswith(".gif"):
                                mime_type = "image/gif"
                            elif file_name.lower().endswith(".webp"):
                                mime_type = "image/webp"
                            else:
                                mime_type = "image/png"

                            img_info += f"\n     å®Œæ•´ Base64: data:{mime_type};base64,{img_base64}"

                except Exception as e:
                    debug_log(f"åœ–ç‰‡ {i} Base64 è™•ç†å¤±æ•—: {e}")

            text_parts.append(img_info)

        # æ·»åŠ å…¼å®¹æ€§èªªæ˜
        text_parts.append(
            "\nğŸ’¡ æ³¨æ„ï¼šå¦‚æœ AI åŠ©æ‰‹ç„¡æ³•é¡¯ç¤ºåœ–ç‰‡ï¼Œåœ–ç‰‡æ•¸æ“šå·²åŒ…å«åœ¨ä¸Šè¿° Base64 ä¿¡æ¯ä¸­ã€‚"
        )

    return "\n\n".join(text_parts) if text_parts else "ç”¨æˆ¶æœªæä¾›ä»»ä½•å›é¥‹å…§å®¹ã€‚"


def process_images(images_data: list[dict]) -> list[MCPImage]:
    """
    è™•ç†åœ–ç‰‡è³‡æ–™ï¼Œè½‰æ›ç‚º MCP åœ–ç‰‡å°è±¡

    Args:
        images_data: åœ–ç‰‡è³‡æ–™åˆ—è¡¨

    Returns:
        List[MCPImage]: MCP åœ–ç‰‡å°è±¡åˆ—è¡¨
    """
    mcp_images = []

    for i, img in enumerate(images_data, 1):
        try:
            if not img.get("data"):
                debug_log(f"åœ–ç‰‡ {i} æ²’æœ‰è³‡æ–™ï¼Œè·³é")
                continue

            # æª¢æŸ¥æ•¸æ“šé¡å‹ä¸¦ç›¸æ‡‰è™•ç†
            if isinstance(img["data"], bytes):
                # å¦‚æœæ˜¯åŸå§‹ bytes æ•¸æ“šï¼Œç›´æ¥ä½¿ç”¨
                image_bytes = img["data"]
                debug_log(
                    f"åœ–ç‰‡ {i} ä½¿ç”¨åŸå§‹ bytes æ•¸æ“šï¼Œå¤§å°: {len(image_bytes)} bytes"
                )
            elif isinstance(img["data"], str):
                # å¦‚æœæ˜¯ base64 å­—ç¬¦ä¸²ï¼Œé€²è¡Œè§£ç¢¼
                image_bytes = base64.b64decode(img["data"])
                debug_log(f"åœ–ç‰‡ {i} å¾ base64 è§£ç¢¼ï¼Œå¤§å°: {len(image_bytes)} bytes")
            else:
                debug_log(f"åœ–ç‰‡ {i} æ•¸æ“šé¡å‹ä¸æ”¯æ´: {type(img['data'])}")
                continue

            if len(image_bytes) == 0:
                debug_log(f"åœ–ç‰‡ {i} æ•¸æ“šç‚ºç©ºï¼Œè·³é")
                continue

            # æ ¹æ“šæ–‡ä»¶åæ¨æ–·æ ¼å¼
            file_name = img.get("name", "image.png")
            if file_name.lower().endswith((".jpg", ".jpeg")):
                image_format = "jpeg"
            elif file_name.lower().endswith(".gif"):
                image_format = "gif"
            else:
                image_format = "png"  # é»˜èªä½¿ç”¨ PNG

            # å‰µå»º MCPImage å°è±¡
            mcp_image = MCPImage(data=image_bytes, format=image_format)
            mcp_images.append(mcp_image)

            debug_log(f"åœ–ç‰‡ {i} ({file_name}) è™•ç†æˆåŠŸï¼Œæ ¼å¼: {image_format}")

        except Exception as e:
            # ä½¿ç”¨çµ±ä¸€éŒ¯èª¤è™•ç†ï¼ˆä¸å½±éŸ¿ JSON RPCï¼‰
            error_id = ErrorHandler.log_error_with_context(
                e,
                context={"operation": "åœ–ç‰‡è™•ç†", "image_index": i},
                error_type=ErrorType.FILE_IO,
            )
            debug_log(f"åœ–ç‰‡ {i} è™•ç†å¤±æ•— [éŒ¯èª¤ID: {error_id}]: {e}")

    debug_log(f"å…±è™•ç† {len(mcp_images)} å¼µåœ–ç‰‡")
    return mcp_images


# ===== MCP å·¥å…·å®šç¾© =====
@mcp.tool()
async def interactive_feedback(
    project_directory: Annotated[str, Field(description="å°ˆæ¡ˆç›®éŒ„è·¯å¾‘")] = ".",
    summary: Annotated[
        str, Field(description="AI å·¥ä½œå®Œæˆçš„æ‘˜è¦èªªæ˜")
    ] = "æˆ‘å·²å®Œæˆäº†æ‚¨è«‹æ±‚çš„ä»»å‹™ã€‚",
    timeout: Annotated[int, Field(description="ç­‰å¾…ç”¨æˆ¶å›é¥‹çš„è¶…æ™‚æ™‚é–“ï¼ˆç§’ï¼‰")] = 600,
) -> list:
    """Interactive feedback collection tool for LLM agents.

    USAGE RULES:
    1. During any process, task, or conversation, whether asking, replying, or completing phased tasks, you must call this tool to ask for feedback.
    2. Unless receiving termination instructions, all steps must repeatedly call this tool.
    3. Whenever user feedback is received, if the feedback content is not empty, you must call this tool again and adjust behavior based on the feedback content.
    4. Only when the user explicitly indicates "end" or "no more interaction needed" can you stop calling this tool, and the process is considered complete.
    5. You should summarize what have done, and provide project directory through args to let user know what you have done to provide feedback for next step.

    Args:
        project_directory: Project directory path for context
        summary: Summary of AI work completed for user review
        timeout: Timeout in seconds for waiting user feedback (default: 600 seconds)

    Returns:
        list: List containing TextContent and MCPImage objects representing user feedback
    """
    # ç’°å¢ƒåµæ¸¬
    is_remote = is_remote_environment()
    is_wsl = is_wsl_environment()

    debug_log(f"ç’°å¢ƒåµæ¸¬çµæœ - é ç«¯: {is_remote}, WSL: {is_wsl}")
    debug_log("ä½¿ç”¨ä»‹é¢: Web UI")

    try:
        # ç¢ºä¿å°ˆæ¡ˆç›®éŒ„å­˜åœ¨
        if not os.path.exists(project_directory):
            project_directory = os.getcwd()
        project_directory = os.path.abspath(project_directory)

        # ä½¿ç”¨ Web æ¨¡å¼
        debug_log("å›é¥‹æ¨¡å¼: web")

        result = await launch_web_feedback_ui(project_directory, summary, timeout)

        # è™•ç†å–æ¶ˆæƒ…æ³
        if not result:
            return [TextContent(type="text", text="ç”¨æˆ¶å–æ¶ˆäº†å›é¥‹ã€‚")]

        # å„²å­˜è©³ç´°çµæœ
        save_feedback_to_file(result)

        # å»ºç«‹å›é¥‹é …ç›®åˆ—è¡¨
        feedback_items = []

        # æ·»åŠ æ–‡å­—å›é¥‹
        if (
            result.get("interactive_feedback")
            or result.get("command_logs")
            or result.get("images")
        ):
            feedback_text = create_feedback_text(result)
            feedback_items.append(TextContent(type="text", text=feedback_text))
            debug_log("æ–‡å­—å›é¥‹å·²æ·»åŠ ")

        # æ·»åŠ åœ–ç‰‡å›é¥‹
        if result.get("images"):
            mcp_images = process_images(result["images"])
            # ä¿®å¾© arg-type éŒ¯èª¤ - ç›´æ¥æ“´å±•åˆ—è¡¨
            feedback_items.extend(mcp_images)
            debug_log(f"å·²æ·»åŠ  {len(mcp_images)} å¼µåœ–ç‰‡")

        # ç¢ºä¿è‡³å°‘æœ‰ä¸€å€‹å›é¥‹é …ç›®
        if not feedback_items:
            feedback_items.append(
                TextContent(type="text", text="ç”¨æˆ¶æœªæä¾›ä»»ä½•å›é¥‹å…§å®¹ã€‚")
            )

        debug_log(f"å›é¥‹æ”¶é›†å®Œæˆï¼Œå…± {len(feedback_items)} å€‹é …ç›®")
        return feedback_items

    except Exception as e:
        # ä½¿ç”¨çµ±ä¸€éŒ¯èª¤è™•ç†ï¼Œä½†ä¸å½±éŸ¿ JSON RPC éŸ¿æ‡‰
        error_id = ErrorHandler.log_error_with_context(
            e,
            context={"operation": "å›é¥‹æ”¶é›†", "project_dir": project_directory},
            error_type=ErrorType.SYSTEM,
        )

        # ç”Ÿæˆç”¨æˆ¶å‹å¥½çš„éŒ¯èª¤ä¿¡æ¯
        user_error_msg = ErrorHandler.format_user_error(e, include_technical=False)
        debug_log(f"å›é¥‹æ”¶é›†éŒ¯èª¤ [éŒ¯èª¤ID: {error_id}]: {e!s}")

        return [TextContent(type="text", text=user_error_msg)]


async def launch_web_feedback_ui(project_dir: str, summary: str, timeout: int) -> dict:
    """
    å•Ÿå‹• Web UI æ”¶é›†å›é¥‹ï¼Œæ”¯æ´è‡ªè¨‚è¶…æ™‚æ™‚é–“

    Args:
        project_dir: å°ˆæ¡ˆç›®éŒ„è·¯å¾‘
        summary: AI å·¥ä½œæ‘˜è¦
        timeout: è¶…æ™‚æ™‚é–“ï¼ˆç§’ï¼‰

    Returns:
        dict: æ”¶é›†åˆ°çš„å›é¥‹è³‡æ–™
    """
    debug_log(f"å•Ÿå‹• Web UI ä»‹é¢ï¼Œè¶…æ™‚æ™‚é–“: {timeout} ç§’")

    try:
        # ä½¿ç”¨æ–°çš„ web æ¨¡çµ„
        from .web import launch_web_feedback_ui as web_launch

        # å‚³é timeout åƒæ•¸çµ¦ Web UI
        return await web_launch(project_dir, summary, timeout)
    except ImportError as e:
        # ä½¿ç”¨çµ±ä¸€éŒ¯èª¤è™•ç†
        error_id = ErrorHandler.log_error_with_context(
            e,
            context={"operation": "Web UI æ¨¡çµ„å°å…¥", "module": "web"},
            error_type=ErrorType.DEPENDENCY,
        )
        user_error_msg = ErrorHandler.format_user_error(
            e, ErrorType.DEPENDENCY, include_technical=False
        )
        debug_log(f"Web UI æ¨¡çµ„å°å…¥å¤±æ•— [éŒ¯èª¤ID: {error_id}]: {e}")

        return {
            "command_logs": "",
            "interactive_feedback": user_error_msg,
            "images": [],
        }


@mcp.tool()
def get_system_info() -> str:
    """
    ç²å–ç³»çµ±ç’°å¢ƒè³‡è¨Š

    Returns:
        str: JSON æ ¼å¼çš„ç³»çµ±è³‡è¨Š
    """
    is_remote = is_remote_environment()
    is_wsl = is_wsl_environment()

    system_info = {
        "å¹³å°": sys.platform,
        "Python ç‰ˆæœ¬": sys.version.split()[0],
        "WSL ç’°å¢ƒ": is_wsl,
        "é ç«¯ç’°å¢ƒ": is_remote,
        "ä»‹é¢é¡å‹": "Web UI",
        "ç’°å¢ƒè®Šæ•¸": {
            "SSH_CONNECTION": os.getenv("SSH_CONNECTION"),
            "SSH_CLIENT": os.getenv("SSH_CLIENT"),
            "DISPLAY": os.getenv("DISPLAY"),
            "VSCODE_INJECTION": os.getenv("VSCODE_INJECTION"),
            "SESSIONNAME": os.getenv("SESSIONNAME"),
            "WSL_DISTRO_NAME": os.getenv("WSL_DISTRO_NAME"),
            "WSL_INTEROP": os.getenv("WSL_INTEROP"),
            "WSLENV": os.getenv("WSLENV"),
        },
    }

    return json.dumps(system_info, ensure_ascii=False, indent=2)


# ===== Autonomous Lab MCP Tools =====

@mcp.tool()
async def autolab_init(
    project_directory: Annotated[str, Field(description="Project directory path")] = ".",
    idea: Annotated[str, Field(description="Research project idea and context")] = "",
    title: Annotated[str, Field(description="Paper title")] = "TITLE",
) -> str:
    """Initialize an Autonomous Lab project.

    Creates .autolab/ directory with state, profiles, and meeting log.
    Creates paper/ directory with LaTeX template.
    Creates working directories: data/, scripts/, figures/, results/.

    Call this once at the start of a new research project.

    Args:
        project_directory: Path to the project directory
        idea: The research idea, context, and any preliminary data description
        title: Working title for the paper

    Returns:
        str: Confirmation message with instructions to call autolab_next
    """
    from .lab.latex_template import create_paper_structure
    from .lab.state import init_project

    project_directory = os.path.abspath(project_directory)

    if not idea.strip():
        return "ERROR: 'idea' parameter is required. Provide the research idea and context."

    try:
        state = init_project(project_directory, idea)
        create_paper_structure(project_directory, title)

        return (
            f"Autonomous Lab initialized in {project_directory}\n\n"
            f"Created:\n"
            f"  .autolab/ -- state, profiles, meeting log\n"
            f"  paper/ -- LaTeX template ({title})\n"
            f"  scripts/, figures/, results/ -- working directories\n\n"
            f"State: iteration={state['iteration']}, next_role={state['next_role']}\n\n"
            f"Next step: Call autolab_next to get the PI's first prompt."
        )
    except Exception as e:
        return f"ERROR initializing project: {e}"


@mcp.tool()
async def autolab_next(
    project_directory: Annotated[str, Field(description="Project directory path")] = ".",
) -> str:
    """Get the next role prompt for the Autonomous Lab session.

    Reads the current state to determine whose turn it is (PI or Trainee),
    assembles context (idea, profiles, meeting history, file listings),
    and returns a detailed role prompt.

    The AI should then follow the returned prompt exactly, acting as
    the specified role (PI or Trainee).

    Call flow: autolab_next -> (AI acts as role) -> autolab_record -> autolab_next -> ...

    Args:
        project_directory: Path to the project directory

    Returns:
        str: The role prompt to follow
    """
    from .lab.prompts import build_pi_prompt, build_reviewer_prompt, build_trainee_prompt
    from .lab.state import (
        get_meeting_summaries,
        get_paper_progress,
        get_recent_meetings,
        load_idea,
        load_profile,
        load_state,
        scan_project_files,
    )

    project_directory = os.path.abspath(project_directory)

    try:
        state = load_state(project_directory)
    except FileNotFoundError as e:
        return f"ERROR: {e}"

    idea = load_idea(project_directory)
    role = state["next_role"]
    iteration = state["iteration"]
    user_feedback = state.get("user_feedback", "")
    meeting_history = get_recent_meetings(project_directory, n=3)
    summaries = get_meeting_summaries(project_directory)
    file_listings = scan_project_files(project_directory)

    # Check if paper review is needed
    if state.get("status") == "ready_for_review":
        paper_progress = get_paper_progress(project_directory)
        prompt = build_reviewer_prompt(paper_progress, file_listings, meeting_history)
        return (
            f"[AUTOLAB] REVIEWER MODE -- Paper Review\n"
            f"Iteration: {iteration}\n\n"
            f"{prompt}"
        )

    # Build role-specific prompt
    profile = load_profile(project_directory, role)

    if role == "pi":
        prompt = build_pi_prompt(
            idea=idea,
            profile=profile,
            meeting_history=meeting_history,
            summaries=summaries,
            file_listings=file_listings,
            user_feedback=user_feedback,
            iteration=iteration,
        )
    else:
        prompt = build_trainee_prompt(
            idea=idea,
            profile=profile,
            meeting_history=meeting_history,
            summaries=summaries,
            file_listings=file_listings,
            user_feedback=user_feedback,
            iteration=iteration,
        )

    return (
        f"[AUTOLAB] {role.upper()} TURN -- Iteration {iteration}\n\n"
        f"{prompt}"
    )


@mcp.tool()
async def autolab_record(
    project_directory: Annotated[str, Field(description="Project directory path")] = ".",
    role: Annotated[str, Field(description="Role that just acted: 'pi' or 'trainee'")] = "",
    summary: Annotated[str, Field(description="Brief summary of what was done this turn")] = "",
    content: Annotated[str, Field(description="Full content of the turn (review, agenda, results, etc.)")] = "",
    status: Annotated[str, Field(description="Status: 'continue' or 'ready_for_review'")] = "continue",
    timeout: Annotated[int, Field(description="Timeout in seconds for user feedback")] = 600,
) -> str:
    """Record a completed turn and show the monitoring UI for user feedback.

    This tool:
    1. Saves the turn to meeting_log.md
    2. Updates state.json (advance iteration, flip role, store status)
    3. Compresses old meetings every 6 turns
    4. Opens the web feedback UI with a rich dashboard summary
    5. Waits for user feedback (or timeout = auto-continue)
    6. Stores user feedback in state.json for the next turn

    Call this AFTER completing your role actions (as PI or Trainee).

    Args:
        project_directory: Path to the project directory
        role: Which role just completed: 'pi' or 'trainee'
        summary: Brief summary of actions taken
        content: Full structured content of the turn
        status: 'continue' to keep iterating, 'ready_for_review' when paper is done
        timeout: Seconds to wait for user feedback (default 600)

    Returns:
        str: User feedback text, or empty string if auto-continued
    """
    from .lab.state import (
        append_meeting_log,
        compress_old_meetings,
        get_paper_progress,
        load_state,
        save_state,
        scan_project_files,
        COMPRESS_EVERY,
    )

    project_directory = os.path.abspath(project_directory)

    if role not in ("pi", "trainee"):
        return "ERROR: role must be 'pi' or 'trainee'"

    try:
        state = load_state(project_directory)
    except FileNotFoundError as e:
        return f"ERROR: {e}"

    iteration = state["iteration"]

    # 1. Append to meeting log
    append_meeting_log(project_directory, role, iteration, summary, content)

    # 2. Update state
    next_role = "trainee" if role == "pi" else "pi"
    new_iteration = iteration + (1 if role == "trainee" else 0)
    state["iteration"] = new_iteration
    state["next_role"] = next_role
    state["status"] = status
    state["user_feedback"] = ""  # Clear previous feedback
    save_state(project_directory, state)

    # 3. Compress old meetings periodically
    if new_iteration > 0 and new_iteration % COMPRESS_EVERY == 0:
        compress_old_meetings(project_directory)

    # 4. Build dashboard summary for the web UI
    file_listings = scan_project_files(project_directory)
    paper_progress = get_paper_progress(project_directory)

    # Build a rich markdown summary for the feedback UI
    figures_list = file_listings.get("figures", [])
    figures_str = "\n".join(f"- {f}" for f in figures_list[:20]) if figures_list else "None yet"

    paper_str_parts = []
    for section, info in paper_progress.items():
        if info["exists"] and info["words"] > 0:
            paper_str_parts.append(f"  {section}: {info['words']} words")
        else:
            paper_str_parts.append(f"  {section}: --")
    paper_str = "\n".join(paper_str_parts)

    dashboard_summary = (
        f"[AUTOLAB]\n\n"
        f"# Autonomous Lab â€” Iteration {new_iteration}\n\n"
        f"**Completed:** {role.upper()} turn\n"
        f"**Next:** {next_role.upper()} turn\n"
        f"**Status:** {status}\n\n"
        f"## Turn Summary\n\n{summary}\n\n"
        f"## Figures\n\n{figures_str}\n\n"
        f"## Paper Progress\n\n{paper_str}\n\n"
        f"---\n\n"
        f"*Provide feedback below, or leave empty and submit to continue.*"
    )

    # 5. Launch the feedback UI (reusing mcp-feedback-enhanced's web UI)
    try:
        result = await launch_web_feedback_ui(project_directory, dashboard_summary, timeout)

        user_feedback_text = ""
        if result and result.get("interactive_feedback"):
            user_feedback_text = result["interactive_feedback"].strip()

        # 6. Store feedback in state
        state = load_state(project_directory)
        state["user_feedback"] = user_feedback_text
        save_state(project_directory, state)

        if user_feedback_text:
            return f"User feedback received:\n\n{user_feedback_text}"
        else:
            return "No user feedback. Continuing to next turn."

    except TimeoutError:
        return "Feedback timeout. Continuing to next turn."
    except Exception as e:
        debug_log(f"Feedback UI error: {e}")
        return f"Feedback UI error: {e}. Continuing to next turn."


@mcp.tool()
async def autolab_status(
    project_directory: Annotated[str, Field(description="Project directory path")] = ".",
) -> str:
    """Get the current status of an Autonomous Lab project.

    Returns the current state, file listings, paper progress,
    and a summary of recent meetings.

    Args:
        project_directory: Path to the project directory

    Returns:
        str: Formatted status report
    """
    from .lab.state import (
        get_paper_progress,
        get_recent_meetings,
        load_state,
        scan_project_files,
    )

    project_directory = os.path.abspath(project_directory)

    try:
        state = load_state(project_directory)
    except FileNotFoundError as e:
        return f"ERROR: {e}"

    file_listings = scan_project_files(project_directory)
    paper_progress = get_paper_progress(project_directory)
    recent = get_recent_meetings(project_directory, n=2)

    # Format file counts
    file_counts = {k: len(v) for k, v in file_listings.items()}

    # Format paper progress
    paper_lines = []
    for section, info in paper_progress.items():
        if info["exists"] and info["words"] > 0:
            paper_lines.append(f"  {section}: {info['words']} words")
        elif info["exists"]:
            paper_lines.append(f"  {section}: placeholder only")
        else:
            paper_lines.append(f"  {section}: not created")

    report = (
        f"# Autonomous Lab Status\n\n"
        f"**Iteration:** {state['iteration']}\n"
        f"**Next role:** {state['next_role']}\n"
        f"**Status:** {state['status']}\n"
        f"**Last updated:** {state.get('last_updated', 'unknown')}\n\n"
        f"## File Counts\n"
        f"  data: {file_counts.get('data', 0)} files\n"
        f"  scripts: {file_counts.get('scripts', 0)} files\n"
        f"  figures: {file_counts.get('figures', 0)} files\n"
        f"  results: {file_counts.get('results', 0)} files\n"
        f"  paper: {file_counts.get('paper', 0)} files\n\n"
        f"## Paper Progress\n"
        + "\n".join(paper_lines)
        + "\n\n"
        f"## Recent Meetings\n\n{recent if recent.strip() else 'No meetings yet.'}\n"
    )

    if state.get("user_feedback"):
        report += f"\n## Pending User Feedback\n\n{state['user_feedback']}\n"

    return report


# ===== Main entry point =====
def main():
    """ä¸»è¦å…¥å£é»ï¼Œç”¨æ–¼å¥—ä»¶åŸ·è¡Œ
    æ”¶é›†ç”¨æˆ¶çš„äº’å‹•å›é¥‹ï¼Œæ”¯æ´æ–‡å­—å’Œåœ–ç‰‡
    æ­¤å·¥å…·ä½¿ç”¨ Web UI ä»‹é¢æ”¶é›†ç”¨æˆ¶å›é¥‹ï¼Œæ”¯æ´æ™ºèƒ½ç’°å¢ƒæª¢æ¸¬ã€‚

    ç”¨æˆ¶å¯ä»¥ï¼š
    1. åŸ·è¡Œå‘½ä»¤ä¾†é©—è­‰çµæœ
    2. æä¾›æ–‡å­—å›é¥‹
    3. ä¸Šå‚³åœ–ç‰‡ä½œç‚ºå›é¥‹
    4. æŸ¥çœ‹ AI çš„å·¥ä½œæ‘˜è¦

    èª¿è©¦æ¨¡å¼ï¼š
    - è¨­ç½®ç’°å¢ƒè®Šæ•¸ MCP_DEBUG=true å¯å•Ÿç”¨è©³ç´°èª¿è©¦è¼¸å‡º
    - ç”Ÿç”¢ç’°å¢ƒå»ºè­°é—œé–‰èª¿è©¦æ¨¡å¼ä»¥é¿å…è¼¸å‡ºå¹²æ“¾


    """
    # æª¢æŸ¥æ˜¯å¦å•Ÿç”¨èª¿è©¦æ¨¡å¼
    debug_enabled = os.getenv("MCP_DEBUG", "").lower() in ("true", "1", "yes", "on")

    if debug_enabled:
        debug_log("ğŸš€ å•Ÿå‹•äº’å‹•å¼å›é¥‹æ”¶é›† MCP æœå‹™å™¨")
        debug_log(f"   æœå‹™å™¨åç¨±: {SERVER_NAME}")
        debug_log(f"   ç‰ˆæœ¬: {__version__}")
        debug_log(f"   å¹³å°: {sys.platform}")
        debug_log(f"   ç·¨ç¢¼åˆå§‹åŒ–: {'æˆåŠŸ' if _encoding_initialized else 'å¤±æ•—'}")
        debug_log(f"   é ç«¯ç’°å¢ƒ: {is_remote_environment()}")
        debug_log(f"   WSL ç’°å¢ƒ: {is_wsl_environment()}")
        debug_log("   Interface: Web UI")
        debug_log("   ç­‰å¾…ä¾†è‡ª AI åŠ©æ‰‹çš„èª¿ç”¨...")
        debug_log("æº–å‚™å•Ÿå‹• MCP ä¼ºæœå™¨...")
        debug_log("èª¿ç”¨ mcp.run()...")

    try:
        # ä½¿ç”¨æ­£ç¢ºçš„ FastMCP API
        mcp.run()
    except KeyboardInterrupt:
        if debug_enabled:
            debug_log("æ”¶åˆ°ä¸­æ–·ä¿¡è™Ÿï¼Œæ­£å¸¸é€€å‡º")
        sys.exit(0)
    except Exception as e:
        if debug_enabled:
            debug_log(f"MCP æœå‹™å™¨å•Ÿå‹•å¤±æ•—: {e}")
            import traceback

            debug_log(f"è©³ç´°éŒ¯èª¤: {traceback.format_exc()}")
        sys.exit(1)


if __name__ == "__main__":
    main()
